<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>docs</title>
    <link>https://mkusaka.github.io/docs/public/</link>
    <description>Recent content on docs</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 09 Feb 2019 02:05:14 +0900</lastBuildDate>
    
	<atom:link href="https://mkusaka.github.io/docs/public/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>section1</title>
      <link>https://mkusaka.github.io/docs/public/alife/section1/</link>
      <pubDate>Sun, 10 Feb 2019 17:47:28 +0900</pubDate>
      
      <guid>https://mkusaka.github.io/docs/public/alife/section1/</guid>
      <description>これはなに ALifeの1章まとめ
概要 歴史や系譜など、ALifeの位置づけの説明。
1.1 科学としての生命の定義 工学×○○という形で生命に対する可能性は広がってきた。 ALifeは生命自体を計算というパラダイムで捉えることができるかどうか？生命とは何か？という課題と向き合う領域。
1.2 人工生命は実験数学である ALife(人工生命)の誕生は1986年のクリストファー・ラントンまで遡る。 ALifeは既存の生命を含むような「ありえたかもしれない生命」を探求することで、生命の形を探求するアプローチを取る 計算機の性能が向上し、大規模なシミュレーションができるようになった 抽象的な生命を具体的に計算できる研究(=ALife)ができるように
1.3 生命の計算 チューリングは抽象的な計算可能という概念に対して、チューリングマシンという概念とともに定義を与えた
1.3.1 生命に必要な計算 生命活動は計算可能とは限らないので、チューリングマシンで扱えるとは限らない チューリングマシンは時間の考慮がない(無限にあると仮定する)ので、有限時間の現実には当てはめにくい 物理世界であるようなバグ(猫が膝に乗って中断とか)はチューリングマシンでは想定されていない
生命は環境の変化に柔軟に対応する「ロバストネス」が存在する
1.3.2 センサーから運動へのマッピング 生命活動をするためにはセンサーから必要な情報を取り出し、動く必要がある
def: 感覚運動カップリング
センサーからの情報と身体の運動のマッピングのこと、またはそのパターン抽出  センサーからの情報抽出をDNNで行うと効果的
DNNは学習後は変更しにくい？などの欠点があり、LSTMなどいろいろなものを取り入れてみているが、うまく動くとは限らない
前もって作り込んでおかない、柔軟なもの。コンラッドによる 生命的な計算 という考えが大事
1.4 サイバネティクスから人工生命へ スキップ</description>
    </item>
    
    <item>
      <title>README</title>
      <link>https://mkusaka.github.io/docs/public/alife/readme/</link>
      <pubDate>Sun, 10 Feb 2019 17:44:39 +0900</pubDate>
      
      <guid>https://mkusaka.github.io/docs/public/alife/readme/</guid>
      <description>これはなに O&amp;rsquo;Reilly Japan - 作って動かすALife ついでのTensorflow勉強記録
序文 ゼロからはじめるディープラーニングを読んだあとにTensorflowを読みたくなったため、alifeに手を出すことにしました。 200ページほどなのですぐ読めると信じています。</description>
    </item>
    
    <item>
      <title>Sklearn</title>
      <link>https://mkusaka.github.io/docs/public/tensorflow_and_scikit-learn/contents/sklearn/</link>
      <pubDate>Sun, 10 Feb 2019 14:14:38 +0900</pubDate>
      
      <guid>https://mkusaka.github.io/docs/public/tensorflow_and_scikit-learn/contents/sklearn/</guid>
      <description>概要 sklearnに関して調べたものはこちらに集約していく。
詳細 クラス sklearn.preprocessing.Imputer 欠損値の補完を行う。
引数  strategy: str  median: axisに依存した欠損値の中央値で代替する 実際に計算する際はテキスト属性などを削除したdataframeを渡すぽい   インスタンスメソッド  fit:  引数に訓練データを渡してインスタンスを適合させられる   ※このクラス自体はSimpleImputerに変わるらしいとdeprecation warningが出ていた。
/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.  情報元 sklearn.preprocessing.Imputer — scikit-learn 0.17 文档</description>
    </item>
    
    <item>
      <title>2_5</title>
      <link>https://mkusaka.github.io/docs/public/tensorflow_and_scikit-learn/contents/2_5/</link>
      <pubDate>Sun, 10 Feb 2019 13:06:34 +0900</pubDate>
      
      <guid>https://mkusaka.github.io/docs/public/tensorflow_and_scikit-learn/contents/2_5/</guid>
      <description> 概要 機械学習アルゴリズムのためのデータ準備
詳細 データのクリーニング 欠損特徴量の処理機構 通常欠損特徴量を処理できないので、対応するための関数を作る必要性がある。
pandasの対処方法例  欠測のある区域を取り除く ⇔ pandas.DataFrame.dropna() 属性全体を取り除く ⇔ pandas.DataFrame.drop() 何らかの値(0, 平均etc)を設定する ⇔ pandas.DataFrame.fillna()  システム評価などで再利用する可能性があるため、使用した中央値は残しておいたほうが良い   scikit learnの対処例 Imputerを使用するとうまく処理してくれる - 数値データのみのdataframeを渡す必要がある
link  notebook  </description>
    </item>
    
    <item>
      <title>Toggl_pomodoro</title>
      <link>https://mkusaka.github.io/docs/public/posts/toggl_pomodoro/</link>
      <pubDate>Sun, 10 Feb 2019 12:55:43 +0900</pubDate>
      
      <guid>https://mkusaka.github.io/docs/public/posts/toggl_pomodoro/</guid>
      <description>TBD pomodoroとtogglの併用について書く予定</description>
    </item>
    
    <item>
      <title>Pandas</title>
      <link>https://mkusaka.github.io/docs/public/tensorflow_and_scikit-learn/contents/pandas/</link>
      <pubDate>Sun, 10 Feb 2019 01:09:39 +0900</pubDate>
      
      <guid>https://mkusaka.github.io/docs/public/tensorflow_and_scikit-learn/contents/pandas/</guid>
      <description>概要 pandasに関して調べたものはこちらに集約していく。
詳細 メソッド 使用した箇所のみ記載する。 全部記載はできないので、他の使い方など詳細は情報元のlinkを参照。
pandas.DataFrame.plot dataframeを図示するメソッド
引数  kind: 図示する形式(散布図なのか折れ線図7日)などを指定する  &amp;ldquo;scatter&amp;rdquo; の場合は散布図 etc..  x: x軸のラベルを指定。デフォルトはNone y: y軸のラベルを指定。デフォルトはNone alpha: 密度が高いところを見やすくする。  (ここだけmatplotlibの引数なのかな？)  c: ドキュメントに見当たらない、、 label: ドキュメントに見当たらない、、 cmap: ドキュメントに見当たらない、、 figsize: ドキュメントに見当たらない、、 colorbar: カラーバーの表示  情報元  pandas.DataFrame.plot — pandas 0.24.1 documentation axes — Matplotlib 3.0.2 documentation  pandas.DataFrame.corr 列同士の相関を計算する。計算をする際にNAやnullは考慮されない
情報元  pandas.DataFrame.corr — pandas 0.24.1 documentation  pandas.plotting.scatter_matrix 各データ同士の散布図を作成する
引数  第1引数: データフレーム figsize: tupleで図の大きさを指定する  情報元  pandas.</description>
    </item>
    
    <item>
      <title>2_4</title>
      <link>https://mkusaka.github.io/docs/public/tensorflow_and_scikit-learn/contents/2_4/</link>
      <pubDate>Sun, 10 Feb 2019 00:46:12 +0900</pubDate>
      
      <guid>https://mkusaka.github.io/docs/public/tensorflow_and_scikit-learn/contents/2_4/</guid>
      <description> 概要 データの可視化の話 - データを可視化することで、対象に対するより深い洞察をする - 2.3章でも概観を見たが、ことをしたが、より深い理解を進める。
詳細 まずやること  訓練セットのみを扱う 訓練セットが大きい場合は抽出して小さくする  図示  plotを使用した結果を見る パターンを見つけやすいように可視化パラメータを操作する必要がある →ある程度地理的な特徴との相関が見えてきそう  相関探し  pandas.DataFrame.corr を使用すると列同士の相関係数を自動で計算してくれる pandas.plotting.scatter_matrix関数で与えたデータ同士の散布図を書くこともできる  属性の組み合わせ試行 機械学習アルゴリズム向けのデータを作成する前にしておきたい処理 - さまざまな属性を結合してみる - 部屋数だけわかっても意味がない - 本当にほしいのは世帯いあたりの部屋数 - 寝室の総数は意味がない - 部屋数と比較するものがほしい
用語 def: テールヘビー
&amp;gt; 借入金の分割返済（貸付金の分割回収）のうち、最後の回だけ多額になる形態です。 ここでは主題以外のデータが多くなること？という感じの様子。 もともと金融関連の用語 http://finagoya.com/%E3%80%90%E7%94%A8%E8%AA%9E%E9%9B%86%E3%80%91%E3%83%86%E3%83%BC%E3%83%AB%E3%83%98%E3%83%93%E3%83%BC/  参考URL </description>
    </item>
    
    <item>
      <title>README</title>
      <link>https://mkusaka.github.io/docs/public/searches/readme/</link>
      <pubDate>Sat, 09 Feb 2019 13:12:33 +0900</pubDate>
      
      <guid>https://mkusaka.github.io/docs/public/searches/readme/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Search_result_document_granularity</title>
      <link>https://mkusaka.github.io/docs/public/posts/search_result_document_granularity/</link>
      <pubDate>Sat, 09 Feb 2019 12:51:44 +0900</pubDate>
      
      <guid>https://mkusaka.github.io/docs/public/posts/search_result_document_granularity/</guid>
      <description> これはなに 調査をする際のドキュメントの粒度について、個人的な現状のベストプラクティスぽいものをまとめる
※理想なので毎回これをやるわけではないですが、あとから参照するとこれが今のところ一番良さそうなきはします。
概要 TBD
 課題感  調査をしながらドキュメントを書くとただのログになりがちで再利用性がない  戦略  調査の主題を記載するドキュメントを作成する 調査の思考過程をもとにしたドキュメントの分岐を作成する 思考の分岐 = ドキュメントの分岐として捉える  分岐の例: わからない単語が出てきて調べる 新しいライブラリについて調べる 対象の技術を使ってみたサイトに何が書いてあったのかをまとめる 対象の技術の思想についてまとめる etc&amp;hellip;  すべての情報は主題のドキュメントを頂点としたツリー構造を取る  本質的にはどこが頂点でも変わらない  思考した結果をもとに提出用としてドキュメントを揃える ツリー構造からわかること、どこを頂点とすればよいかを考慮した上でまとめる ピラミッド原則がわかりやすい 思考過程のドキュメントと提出用のドキュメントを相互参照できるようにする  戦略を支えるツール  ドキュメントツールなら何でもいい気がする dropboxpaper notion esa  調査をしながらドキュメントを書くということ  メリット あとに残るので再利用可能 文章のほうがシェアしやすいため集合知としての価値も出てくる デメリット 調査の速度が遅くなる 戦略がないと再利用ができないただの一時情報ができる   </description>
    </item>
    
    <item>
      <title>Stock_and_flow</title>
      <link>https://mkusaka.github.io/docs/public/posts/stock_and_flow/</link>
      <pubDate>Sat, 09 Feb 2019 12:43:19 +0900</pubDate>
      
      <guid>https://mkusaka.github.io/docs/public/posts/stock_and_flow/</guid>
      <description> これはなに ストック情報フロー情報について、普段どういう事を考えているのかをまとめる。 また普段使用しているツールも踏まえ、どういった形の情報整理が正しいかを考える。
概要  ストック情報  あとから参照される可能性の高い情報 メンテナンスを要する  フロー情報  あとから参照される可能性の低い情報 メンテナンスを要さない  チャットシステム ドキュメントシステム 口頭という呪い  口頭で話したことをあとで文章化すればいいものではない  Github Issueはストック情報か？フロー情報か？  ストック情報とフロー情報の間  コラム:コピペの功罪 なんもわからん  詳細 参考URL  フローとストック | サルでもわかるプロジェクト管理入門【プロジェクト管理ツールBacklog】 ストック情報とフロー情報 – イディア：情報デザインと情報アーキテクチャ  </description>
    </item>
    
    <item>
      <title>README</title>
      <link>https://mkusaka.github.io/docs/public/tensorflow_and_scikit-learn/readme/</link>
      <pubDate>Sat, 09 Feb 2019 01:49:09 +0900</pubDate>
      
      <guid>https://mkusaka.github.io/docs/public/tensorflow_and_scikit-learn/readme/</guid>
      <description> 読む本: O&amp;rsquo;Reilly Japan - scikit-learnとTensorFlowによる実践機械学習
参考URL  O&amp;rsquo;Reilly Japan - scikit-learnとTensorFlowによる実践機械学習 notebook置き場  </description>
    </item>
    
  </channel>
</rss>