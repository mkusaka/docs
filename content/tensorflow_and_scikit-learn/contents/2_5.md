---
title: "2_5"
date: 2019-02-10T13:06:34+09:00
draft: false
---

# 概要
機械学習アルゴリズムのためのデータ準備

# 詳細
## データのクリーニング
### 欠損特徴量の処理機構
通常欠損特徴量を処理できないので、対応するための関数を作る必要性がある。

#### pandasの対処方法例
1. 欠測のある区域を取り除く ⇔ pandas.DataFrame.dropna()
2. 属性全体を取り除く ⇔ pandas.DataFrame.drop()
3. 何らかの値(0, 平均etc)を設定する ⇔ pandas.DataFrame.fillna()
  - システム評価などで再利用する可能性があるため、使用した中央値は残しておいたほうが良い

### scikit learnの対処例
Imputerを使用するとうまく処理してくれる
- 数値データのみのdataframeを渡す必要がある

memo: 2.5.2あたりから一旦ざっくり流れを追うのみにする。

### 2.5.3 カスタム変換
- sklearnが対応していない変換は自分で作成する必要がある
- その場合もsklearnの変換器以外の機能を使用する事ができる
  - fit(), transform(), fit_transform() を実装すれば良い(らしい)
  - 詳細は2.5.3を参照

### 2.5.4 特徴量のスケーリング

**def: 特徴量のスケーリング**
```
たぶん大きすぎる/小さすぎる特徴量をスケールしやすいように調整することと思われる(定義見当たらない、、、)

最小最大スケーリングと標準化の二つがある

- データに対して実行する重要な操作の一つ
- 入力が大きくなるとほぼ性能が落ちることに対する対策として用いられる

※ターゲット値のスケーリングは一般には不要(らしい)(なぜ・・・)
```

**def: 最小最大スケーリング**

特徴量のスケーリングの一つ
```
特徴量の値を0から1に収まるように変換する方法。一般に正規化とも呼ばれる操作。
対象の特徴量の値から最小値を引き、(最大値 - 最小値)で割るだけよい。

- sklearnではMinMaxScaler変換機が用意されている。
  - `[0, 1]` 以外の範囲に調整する方法もsklearnは提供している
```

**def: 標準化**
```
特徴量の値の分布が `単位分布` になるように調整する
値から平均を引き、分散で割る操作をするだけで良い。

- 外れ値の影響を受けにくいという特徴がある
- 一方で正規化と異なり値に上限下限が存在しないので、 `[0, 1]` を前提とするアルゴリズムで問題になる場合がある
- sklearnはStarndardScalerと呼ばれる変換器を用意している
```

### 2.5.5 変換パイプライン
複数かつ順序のあるデータ変換を順に実行するPipelineと呼ばれるクラスがsklearnには存在する

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

num_pipeline = Pipeline([
  ('imputer', Imputer(strategy="median")),
  ('attribs_addr', CombinedAttributesAdder()),
  ('std_scaler', StandardScaler()),
])

housing_num_tr = num_pipeline.fit_transform(housing_num)
```

# link
- [notebook](https://github.com/mkusaka/tensorflow_tutorial/blob/master/src/scikit-learn%26TensorFlow/2.5.ipynb)
